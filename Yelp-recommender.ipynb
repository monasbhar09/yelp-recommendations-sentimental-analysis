{"cells":[{"cell_type":"code","source":["spark"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["from pyspark.sql.types import *\nfrom pyspark.sql.functions import *\n\ninputPath = \"dbfs:/mnt/yelp-mount\"\n\n# Since we know the data format already, let's define the schema to speed up processing (no need for Spark to infer schema)\njsonSchema = StructType([ \n  StructField(\"review_id\", StringType(), True), \n  StructField(\"user_id\", StringType(), True) , \n  StructField(\"business_id\", StringType(), True) , \n  StructField(\"stars\", IntegerType(), True) , \n  StructField(\"date\", TimestampType(), True) , \n  StructField(\"text\", StringType(), True), \n  StructField(\"useful\", IntegerType(), True), \n  StructField(\"funny\", IntegerType(), True), \n  StructField(\"cool\", IntegerType(), True) ])\n\n# Stream DataFrame representing data in the JSON files\nstreamInputDF = (\n  spark\n    .readStream\n    .schema(jsonSchema)\n    .option(\"maxFilesPerTrigger\", 1)\n    .json(inputPath)\n)\n\n# Query for counting review grouped by stars\nstreamingCountsDF = (                 \n  streamInputDF\n    .groupBy(\n      streamInputDF.stars, \n      window(streamInputDF.date, \"1 hour\"))\n    .count()\n)\n\nstreamingCountsDF.isStreaming"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["spark.conf.set(\"spark.sql.shuffle.partitions\", \"2\")  # keep the size of shuffles small\n\nquery = (\n  streamingCountsDF\n    .writeStream\n    .format(\"memory\")        # memory = store in-memory table (for testing only in Spark 2.0)\n    .queryName(\"counts\")     # counts = name of the in-memory table\n    .outputMode(\"complete\")  # complete = all the counts should be in the table\n    .start()\n)"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["from time import sleep"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["%sql select stars, date_format(window.end, \"MMM-dd HH:mm\") as time, count from counts order by time, stars"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["sleep(5)  # wait a bit more for more data to be computed"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["%sql select stars, date_format(window.end, \"MMM-dd HH:mm\") as time, count from counts order by time, stars"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["%sql select stars, sum(count) as total_count from counts group by stars order by stars"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":9}],"metadata":{"name":"Assignment3","notebookId":1236743218157963},"nbformat":4,"nbformat_minor":0}
