{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import json\n",
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\n",
    "import math\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def execute(spark, path, state, directory):\n",
    "    df = spark.read.json(path)\n",
    "    df.describe()\n",
    "    df = df.select('*', (df.stars * 2).alias('rescaled_rating'))\n",
    "    df.createOrReplaceTempView(\"user_business_review\")\n",
    "    ratingsDf = spark.sql(\"Select user_unique_user_id, unique_business_id, rescaled_rating from user_business_review\")\n",
    "    (training, testing) = ratingsDf.randomSplit([0.8, 0.2])\n",
    "    ratings = training.rdd.map(lambda l: Rating(int(l[0]), int(l[1]), float(l[2])))\n",
    "    rank = 100\n",
    "    numIterations = 15\n",
    "    model = ALS.train(ratings, rank, numIterations)\n",
    "    testdata = testing.rdd.map(lambda p: (p[0], p[1]))\n",
    "    predictions = model.predictAll(testdata)\n",
    "    p = predictions.toDF()\n",
    "    p.createOrReplaceTempView(\"outcome\")\n",
    "    out = spark.sql(\n",
    "        \"Select u.rescaled_rating, p.* from user_business_review u,\"\n",
    "        \" outcome p where p.user=u.user_unique_user_id and u.unique_business_id=p.product\")\n",
    "\n",
    "    print(\"**********\", math.sqrt(out.rdd.map(lambda x: (x[0] - x[3]) ** 2).mean()), \" ********** \")\n",
    "    model_name = directory + \"/\" + state + \".parquet\"\n",
    "    model.save(spark.sparkContext, model_name)\n",
    "    print(\"********* SAVED MODEL ****** \", model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\"path\" : \"OH_business.json\"},\n",
    "    {\"path\" : \"AZ_business.json\"},\n",
    "    {\"path\" : \"NC_business.json\"},\n",
    "    {\"path\" : \"ON_business.json\"},\n",
    "    {\"path\" : \"NV_business.json\"}\n",
    "  ]\n",
    "\n",
    "base_path = \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESSING : OH_business.json\n",
      "OH_business\n",
      "********** 5.40094655239638  ********** \n",
      "********* SAVED MODEL ******  als-models/OH_business/OH_business.parquet\n",
      "PROCESSING : AZ_business.json\n",
      "AZ_business\n",
      "********** 4.4647040182141815  ********** \n",
      "********* SAVED MODEL ******  als-models/AZ_business/AZ_business.parquet\n",
      "PROCESSING : NC_business.json\n",
      "NC_business\n",
      "********** 5.149190157542628  ********** \n",
      "********* SAVED MODEL ******  als-models/NC_business/NC_business.parquet\n",
      "PROCESSING : ON_business.json\n",
      "ON_business\n",
      "********** 5.179986319199889  ********** \n",
      "********* SAVED MODEL ******  als-models/ON_business/ON_business.parquet\n",
      "PROCESSING : NV_business.json\n",
      "NV_business\n",
      "********** 3.8718235666317473  ********** \n",
      "********* SAVED MODEL ******  als-models/NV_business/NV_business.parquet\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    spark = SparkSession.builder.appName(\"YelBusinessRecommendation\").getOrCreate()\n",
    "\n",
    "    if os.path.exists('als-models'):\n",
    "        shutil.rmtree('als-models')\n",
    "    os.mkdir('als-models')\n",
    "    for file_location in data :\n",
    "        print('PROCESSING :', file_location['path'])\n",
    "        concat_path = file_location['path']\n",
    "        directory = 'als-models/' + file_location['path'].split('.')[0]\n",
    "        print(file_location['path'].split('.')[0])\n",
    "        os.mkdir(directory)\n",
    "        execute(spark, concat_path, file_location['path'].split('.')[0],directory)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "name": "Yelp-MLib-ALS",
  "notebookId": 3518245818612662
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
