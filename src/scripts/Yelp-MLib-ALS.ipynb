{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALS Recommendation Model\n",
    "\n",
    "We used Spark ML to build the ALS Matrix Factorization Model for restaurant recommendation.\n",
    "We have createed for different ALS models (one per state) which we pickle and store in the file system after creation.\n",
    "This model is capable of helping us get restaurant recommendations for an existing user as well recommendation for users when given a restaurant.\n",
    "\n",
    "### Collaborative Filtering\n",
    "\n",
    "Collaborative filtering aims to fill in the missing entries of a user-item association matrix. spark.mllib model-based collaborative filtering, in which users and products are described by a small set of latent factors that can be used to predict missing entries. spark.mllib uses the alternating least squares (ALS) algorithm to learn these latent factors. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import json\n",
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\n",
    "import math\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps for creating ALS Model:\n",
    "\n",
    "1.\tFor each state, we load the json file containing a combined view of user reviews and restaurants\n",
    "2.\tWe select user_id, business_id, and rating and do a 80:20 random split on the data\n",
    "3.\tThe training data is used to train the ALS model\n",
    "4.\tThe tesing data is used to compute the RMSE \n",
    "5.\tThe models are pickled and saved so that it can be consumed by the flask application.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def execute(spark, path, state, directory):\n",
    "    df = spark.read.json(path)\n",
    "    df.describe()\n",
    "    df = df.select('*', (df.stars * 2).alias('rescaled_rating'))\n",
    "    df.createOrReplaceTempView(\"user_business_review\")\n",
    "    ratingsDf = spark.sql(\"Select user_unique_user_id, unique_business_id, rescaled_rating from user_business_review\")\n",
    "    (training, testing) = ratingsDf.randomSplit([0.8, 0.2])\n",
    "    ratings = training.rdd.map(lambda l: Rating(int(l[0]), int(l[1]), float(l[2])))\n",
    "    rank = 100\n",
    "    numIterations = 15\n",
    "    model = ALS.train(ratings, rank, numIterations)\n",
    "    testdata = testing.rdd.map(lambda p: (p[0], p[1]))\n",
    "    predictions = model.predictAll(testdata)\n",
    "    p = predictions.toDF()\n",
    "    p.createOrReplaceTempView(\"outcome\")\n",
    "    out = spark.sql(\n",
    "        \"Select u.rescaled_rating, p.* from user_business_review u,\"\n",
    "        \" outcome p where p.user=u.user_unique_user_id and u.unique_business_id=p.product\")\n",
    "\n",
    "    print(\"**********\", math.sqrt(out.rdd.map(lambda x: (x[0] - x[3]) ** 2).mean()), \" ********** \")\n",
    "    model_name = directory + \"/\" + state + \".parquet\"\n",
    "    model.save(spark.sparkContext, model_name)\n",
    "    print(\"********* SAVED MODEL ****** \", model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtered business review files generated in RecommendationsALS\n",
    "These files are given input to create ALS models based on the state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\"path\" : \"OH_business.json\"},\n",
    "    {\"path\" : \"AZ_business.json\"},\n",
    "    {\"path\" : \"NC_business.json\"},\n",
    "    {\"path\" : \"ON_business.json\"},\n",
    "    {\"path\" : \"NV_business.json\"}\n",
    "  ]\n",
    "\n",
    "base_path = \"/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Spark session and call function to create als-models based on the state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESSING : OH_business.json\n",
      "OH_business\n",
      "********** 5.40094655239638  ********** \n",
      "********* SAVED MODEL ******  als-models/OH_business/OH_business.parquet\n",
      "PROCESSING : AZ_business.json\n",
      "AZ_business\n",
      "********** 4.4647040182141815  ********** \n",
      "********* SAVED MODEL ******  als-models/AZ_business/AZ_business.parquet\n",
      "PROCESSING : NC_business.json\n",
      "NC_business\n",
      "********** 5.149190157542628  ********** \n",
      "********* SAVED MODEL ******  als-models/NC_business/NC_business.parquet\n",
      "PROCESSING : ON_business.json\n",
      "ON_business\n",
      "********** 5.179986319199889  ********** \n",
      "********* SAVED MODEL ******  als-models/ON_business/ON_business.parquet\n",
      "PROCESSING : NV_business.json\n",
      "NV_business\n",
      "********** 3.8718235666317473  ********** \n",
      "********* SAVED MODEL ******  als-models/NV_business/NV_business.parquet\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    spark = SparkSession.builder.appName(\"YelBusinessRecommendation\").getOrCreate()\n",
    "\n",
    "    if os.path.exists('als-models'):\n",
    "        shutil.rmtree('als-models')\n",
    "    os.mkdir('als-models')\n",
    "    for file_location in data :\n",
    "        print('PROCESSING :', file_location['path'])\n",
    "        concat_path = file_location['path']\n",
    "        directory = 'als-models/' + file_location['path'].split('.')[0]\n",
    "        print(file_location['path'].split('.')[0])\n",
    "        os.mkdir(directory)\n",
    "        execute(spark, concat_path, file_location['path'].split('.')[0],directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text in the document by Shrikant Mudholkar, Varsha Bhanushali and Monas Bhar is licensed under CC BY 3.0 https://creativecommons.org/licenses/by/3.0/us/\n",
    "\n",
    "The code in the document by Shrikant Mudholkar, Varsha Bhanushali and Monas Bhar is licensed under the MIT License https://opensource.org/licenses/MIT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "name": "Yelp-MLib-ALS",
  "notebookId": 3518245818612662
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
