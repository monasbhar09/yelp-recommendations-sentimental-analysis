{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\n\nimport json\nfrom pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\nimport math\nimport os\nimport shutil"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["def execute(spark, path, state, directory):\n    df = spark.read.json(path)\n    df = df.select('*', (df.stars * 2).alias('rescaled_rating'))\n    df.createOrReplaceTempView(\"user_business_review\")\n    ratingsDf = spark.sql(\"Select user_unique_user_id, unique_business_id, rescaled_rating from user_business_review\")\n    (training, testing) = ratingsDf.randomSplit([0.8, 0.2])\n    ratings = training.rdd.map(lambda l: Rating(int(l[0]), int(l[1]), float(l[2])))\n    rank = 100\n    numIterations = 15\n    model = ALS.train(ratings, rank, numIterations)\n    testdata = testing.rdd.map(lambda p: (p[0], p[1]))\n    predictions = model.predictAll(testdata)\n    p = predictions.toDF()\n    p.createOrReplaceTempView(\"outcome\")\n    out = spark.sql(\n        \"Select u.rescaled_rating, p.* from user_business_review u,\"\n        \" outcome p where p.user=u.user_unique_user_id and u.unique_business_id=p.product\")\n\n    print(\"**********\", math.sqrt(out.rdd.map(lambda x: (x[0] - x[3]) ** 2).mean()), \" ********** \")\n    model_name = directory + \"/\" + state + \".parquet\"\n    model.save(spark.sparkContext, model_name)\n    print(\"********* SAVED MODEL ****** \", model_name)\n"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["data = [\n    {\"path\" : \"OH_business.json\"},\n    {\"path\" : \"AZ_business.json\"},\n    {\"path\" : \"NC_business.json\"},\n    {\"path\" : \"ON_business.json\"},\n    {\"path\" : \"NV_business.json\"}\n  ]\n\nbase_path = \"/FileStore/\""],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["if __name__ == \"__main__\":\n\n    spark = SparkSession.builder.appName(\"YelBusinessRecommendation\").getOrCreate()\n\n    if os.path.exists('als-models'):\n        shutil.rmtree('als-models')\n    os.mkdir('als-models')\n    for file_location in data :\n        print('PROCESSING :', file_location['path'])\n        concat_path = base_path + file_location['path']\n        directory = 'als-models/' + file_location['path'].split('.')[0]\n        os.mkdir(directory)\n        execute(spark, concat_path, file_location['path'].split('.')[0],directory)\n"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["df = spark.read.json('/FileStore/OH_business.json')"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["%fs rm -r als-models"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":8}],"metadata":{"name":"Yelp-MLib-ALS","notebookId":3518245818612662},"nbformat":4,"nbformat_minor":0}
